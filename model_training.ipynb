{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY24UMsdXXIJ",
        "outputId": "b7a374a9-8182-4180-80c1-063e4f2763a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Read CSV\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/datathon2024/datathon-2024/train.csv', low_memory=False)"
      ],
      "metadata": {
        "id": "bqbj_0YtXgrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary colmuns\n",
        "drop_columns = [\n",
        "    'id'\n",
        "]\n",
        "\n",
        "#, 'Spor Dalindaki Rolunuz Nedir?', 'Uye Oldugunuz Kulubun Ismi' 'Basvuru Yili', 'Cinsiyet', 'Dogum Tarihi', 'Dogum Yeri',\n",
        "\n",
        "train_data_cleaned = train_data.drop(columns=drop_columns)\n",
        "train_data_cleaned.to_csv('/content/drive/MyDrive/datathon2024/datathon-2024/processed_train.csv', index=False)\n",
        "\n",
        "# Load new dataset\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/datathon2024/datathon-2024/processed_train.csv', low_memory=False)"
      ],
      "metadata": {
        "id": "8RDMMK9yXpAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average for column 'Universite Not Ortalamasi'\n",
        "def calculate_average(value):\n",
        "    if isinstance(value, str) and '-' in value:\n",
        "        try:\n",
        "            lower, upper = value.split('-')\n",
        "            average = (float(lower.strip()) + float(upper.strip())) / 2\n",
        "            return average\n",
        "        except ValueError:\n",
        "            return None\n",
        "    return value\n",
        "\n",
        "train_data['Universite Not Ortalamasi'] = train_data['Universite Not Ortalamasi'].apply(calculate_average)\n",
        "train_data['Universite Not Ortalamasi'] = pd.to_numeric(train_data['Universite Not Ortalamasi'], errors='coerce')\n",
        "train_data['Universite Not Ortalamasi'] = train_data['Universite Not Ortalamasi'].fillna(train_data['Universite Not Ortalamasi'].mean())\n",
        "\n",
        "# Save new dataset\n",
        "train_data.to_csv('/content/drive/MyDrive/datathon2024/datathon-2024/processed1_train.csv', index=False)"
      ],
      "metadata": {
        "id": "f9lkMn-lX9i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/datathon2024/datathon-2024/processed1_train.csv', low_memory=False)\n",
        "\n",
        "# Calculate average for numeric columns\n",
        "numeric_cols = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "numeric_imputer = SimpleImputer(strategy='mean')\n",
        "train_data[numeric_cols] = numeric_imputer.fit_transform(train_data[numeric_cols])\n",
        "\n",
        "# Fill missings with most frequent values for categorical columns\n",
        "categorical_cols = train_data.select_dtypes(include=['object']).columns\n",
        "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "train_data[categorical_cols] = categorical_imputer.fit_transform(train_data[categorical_cols])"
      ],
      "metadata": {
        "id": "LDocp_bxYNHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label categorical columns\n",
        "for col in categorical_cols:\n",
        "    encoder = LabelEncoder()\n",
        "    train_data[col] = encoder.fit_transform(train_data[col].astype(str))\n",
        "\n",
        "# IQR method for contradictory values\n",
        "def remove_outliers_iqr(data, column):\n",
        "    Q1 = data[column].quantile(0.25)\n",
        "    Q3 = data[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
        "\n",
        "# Clean contradictory values\n",
        "for col in numeric_cols:\n",
        "    train_data = remove_outliers_iqr(train_data, col)\n",
        "\n",
        "# Delete columns that has a lot of contradictory values\n",
        "missing_ratio = train_data.isnull().mean(axis=1)\n",
        "threshold = 0.5  # %50'den fazla eksik verisi olan satırları sil\n",
        "train_data = train_data[missing_ratio < threshold]\n",
        "\n",
        "# Fill missing values\n",
        "train_data.ffill(inplace=True)\n",
        "train_data.bfill(inplace=True)"
      ],
      "metadata": {
        "id": "MOaeRzAnZHXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "target_col = 'Degerlendirme Puani'\n",
        "\n",
        "features = train_data.drop(columns=[target_col])\n",
        "\n",
        "train_data_non_missing = train_data.dropna(subset=[target_col])\n",
        "train_data_missing = train_data[train_data[target_col].isnull()]\n",
        "\n",
        "model = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "model.fit(train_data_non_missing.drop(columns=[target_col]), train_data_non_missing[target_col])\n",
        "\n",
        "predictions = model.predict(train_data_missing.drop(columns=[target_col]))\n",
        "\n",
        "train_data.loc[train_data[target_col].isnull(), target_col] = predictions\n",
        "\n",
        "train_data.to_csv('/content/drive/MyDrive/datathon2024/datathon-2024/processed2_train.csv', index=False)\n",
        "\n",
        "print(\"Eksik değerler başarıyla tahmin edildi ve veri seti kaydedildi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWw3lDjHZUho",
        "outputId": "64a64723-909b-4d9e-f2f0-b46901c91f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eksik değerler başarıyla tahmin edildi ve veri seti kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Optimization\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2, 0.3],\n",
        "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
        "    'reg_lambda': [1, 1.5, 2]\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb.XGBRegressor(random_state=42),\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=50,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_val = best_model.predict(X_val)\n",
        "print(\"Optimized Validation MSE:\", mean_squared_error(y_val, y_pred_val))\n",
        "\n",
        "test_predictions = best_model.predict(test_data_processed)\n",
        "\n",
        "submission = pd.DataFrame({'id': test_data['id'], 'Degerlendirme Puani': test_predictions})\n",
        "submission.to_csv('/content/drive/MyDrive/datathon2024/datathon-2024/submission_optimized.csv', index=False)\n",
        "\n",
        "print(\"Tahminler başarıyla kaydedildi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWI2EUvnQjVG",
        "outputId": "e20f30d2-7a9a-4e7d-e176-2b2aea5fabf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "Best Parameters: {'subsample': 1.0, 'reg_lambda': 2, 'reg_alpha': 0, 'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05, 'gamma': 0.3, 'colsample_bytree': 0.6}\n",
            "Optimized Validation MSE: 34.48892829283832\n",
            "Tahminler başarıyla kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Veriyi yükleme\n",
        "data = pd.read_csv('/content/drive/MyDrive/datathon2024/datathon-2024/processed2_train.csv')  # Ön işleme yapılmış eğitim verisi\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/datathon2024/datathon-2024/test_x.csv')     # Test verisi\n",
        "\n",
        "# Özellikler ve etiketlerin ayrılması\n",
        "X = data.drop(columns=['Degerlendirme Puani'])  # Özellikler\n",
        "y = data['Degerlendirme Puani']                  # Etiketler\n",
        "\n",
        "# Kategorik verileri sayısal verilere dönüştürme\n",
        "def preprocess_data(df, reference_df=None):\n",
        "    df = pd.get_dummies(df)\n",
        "    if reference_df is not None:\n",
        "        # Referans veri setindeki sütunlarla eşitle\n",
        "        df = df.reindex(columns=reference_df.columns, fill_value=0)\n",
        "    # Eksik verileri doldurma\n",
        "    df.fillna(df.mean(), inplace=True)\n",
        "    return df\n",
        "\n",
        "# Eğitim veri setini işleme\n",
        "X_processed = preprocess_data(X)\n",
        "\n",
        "# Test veri setini işleme, eğitim veri setindeki sütunlarla eşitleme\n",
        "test_data_processed = preprocess_data(test_data, reference_df=X_processed)\n",
        "\n",
        "# Eğitim ve test veri setlerine ayırma\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modeli oluşturma ve eğitme\n",
        "model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Modeli değerlendirme (isteğe bağlı)\n",
        "y_pred_val = model.predict(X_val)\n",
        "print(\"Validation MSE:\", mean_squared_error(y_val, y_pred_val))\n",
        "\n",
        "# Test veri seti üzerinde tahmin yapma\n",
        "test_predictions = model.predict(test_data_processed)\n",
        "\n",
        "# Tahminleri bir CSV dosyasına yazma\n",
        "submission = pd.DataFrame({'id': test_data['id'], 'Degerlendirme Puani': test_predictions})\n",
        "submission.to_csv('/content/drive/MyDrive/datathon2024/datathon-2024/submission4.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oYc_e-LkIsX",
        "outputId": "94d8eb93-cdca-4a36-e79f-9d981b4ab061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MSE: 35.94034923332127\n"
          ]
        }
      ]
    }
  ]
}